{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suivi des métriques avec MLflow\n",
    "\n",
    "Lorsque vous entraînez un modèle avec un script, vous pouvez inclure MLflow dans vos scripts pour suivre tous les paramètres, métriques et artefacts. Lorsque vous exécutez le script en tant que travail dans Azure Machine Learning, vous pouvez passer en revue tous les paramètres d’entrée et les sorties pour chaque exécution.\n",
    "\n",
    "### Comprendre MLflow\n",
    "MLflow est une plateforme open source conçue pour gérer le cycle de vie complet du Machine Learning. Comme elle est open source, elle peut être utilisée lors de la formation de modèles sur différentes plateformes. Ici, nous allons nous pencher sur la façon dont nous pouvons intégrer MLflow à des travaux Azure Machine Learning.\n",
    "\n",
    "Il existe deux options pour suivre les travaux de Machine Learning avec MLflow :\n",
    "\n",
    "Activer la journalisation active à l’aide de mlflow.autolog()\n",
    "Utilisez les fonctions de journalisation pour suivre des métriques personnalisées à l’aide de mlflow.log_*\n",
    "Avant de pouvoir utiliser l’une de ces options, vous devez configurer l’environnement pour utiliser MLflow.\n",
    "\n",
    "### Inclure MLflow dans l’environnement\n",
    "Pour utiliser MLflow pendant le travail de formation, les packages pip mlflow et azureml-mlflow doivent être installés sur le calcul qui exécute le script. Par conséquent, vous devez inclure ces deux packages dans l’environnement. Vous pouvez créer un environnement en faisant référence à un fichier YAML qui décrit l’environnement Conda. Dans le cadre de l’environnement Conda, vous pouvez inclure ces deux packages.\n",
    "\n",
    "Par exemple, dans cet environnement personnalisé, mlflow et azureml-mlflow sont installés à l’aide de pip :\n",
    "```yaml\n",
    "name: mlflow-env\n",
    "channels:\n",
    "  - conda-forge\n",
    "dependencies:\n",
    "  - python=3.8\n",
    "  - pip\n",
    "  - pip:\n",
    "    - numpy\n",
    "    - pandas\n",
    "    - scikit-learn\n",
    "    - matplotlib\n",
    "    - mlflow\n",
    "    - azureml-mlflow\n",
    "```\n",
    "\n",
    "### Activer la journalisation automatique\n",
    "Lorsque vous utilisez l’une des bibliothèques courantes pour le Machine Learning, vous pouvez activer la journalisation de la connexion dans MLflow. La journalisation automatique enregistre les paramètres, les métriques et les artefacts de modèle sans qu’il soit nécessaire de spécifier ce qui doit être consigné.\n",
    "\n",
    "La journalisation automatique est prise en charge pour les bibliothèques suivantes :\n",
    "\n",
    "- Scikit-learn\n",
    "- TensorFlow et Keras\n",
    "- XGBoost\n",
    "- LightGBM\n",
    "- Spark\n",
    "- Fastai\n",
    "- Pytorch\n",
    "Pour activer la journalisation automatique, ajoutez le code suivant à votre script de formation :\n",
    "```python\n",
    "import mlflow\n",
    "mlflow.autolog()\n",
    "```\n",
    "\n",
    "### Journaliser des métriques avec MLflow\n",
    "Dans votre script de formation, vous pouvez décider des métriques personnalisées à consigner avec MLflow.\n",
    "\n",
    "Selon le type de valeur que vous souhaitez consigner, utilisez la commande MLflow pour stocker la métrique avec l’exécution d’expérimentation :\n",
    "- `mlflow.log_param()` : Consignez un paramètre de valeur de clé unique. Utilisez cette fonction pour un paramètre d’entrée que vous souhaitez consigner.\n",
    "- `mlflow.log_metric()`: Consignez une métrique de valeur de clé unique. La valeur doit être un nombre. Utilisez cette fonction pour toute sortie que vous souhaitez stocker avec l’exécution.\n",
    "- `mlflow.log_artifact()` : Consigner un fichier. Utilisez cette fonction pour tout tracé que vous souhaitez consigner et enregistrer en tant que fichier image avant.\n",
    "Pour ajouter MLflow à un script de formation existant, vous pouvez ajouter le code suivant :\n",
    "```python\n",
    "import mlflow\n",
    "\n",
    "mlflow.log_param(\"param1\", value1)\n",
    "mlflow.log_metric(\"rmse\", rmse)\n",
    "mlflow.log_artifact(\"plot.png\")\n",
    "```\n",
    "\n",
    "```python\n",
    "import mlflow\n",
    "\n",
    "reg_rate = 0.1\n",
    "mlflow.log_param(\"Regularization rate\", reg_rate)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Récupérer les métriques avec MLflow dans un notebook\n",
    "Lorsque vous exécutez un script d’entraînement en tant que travail dans Azure Machine Learning et que vous suivez l’entraînement de votre modèle avec MLflow, vous pouvez interroger les exécutions dans un notebook à l’aide de MLflow. L’utilisation de MLflow dans un notebook vous permet de mieux contrôler les exécutions que vous souhaitez récupérer pour les comparer.\n",
    "\n",
    "Lorsque vous utilisez MLflow pour interroger vos exécutions, vous faites référence aux expériences et aux exécutions.\n",
    "\n",
    "### Répertorier toutes les expériences\n",
    "Vous pouvez obtenir toutes les expériences actives dans l’espace de travail à l’aide de MLflow :\n",
    "```python\n",
    "import mlflow\n",
    "\n",
    "# Get a list of all runs in the experiment\n",
    "experiments = mlflow.list_experiments()\n",
    "for exp in experiments:\n",
    "    print(exp.name)\n",
    "\n",
    "# Get\n",
    "experiments = mlflow.list_experiments(max_results=2)\n",
    "for exp in experiments:\n",
    "    print(exp.name)\n",
    "\n",
    "\n",
    "\n",
    "#Si vous souhaitez également récupérer les expériences archivées, incluez l’option ViewType.ALL :\n",
    "from mlflow.entities import ViewType\n",
    "\n",
    "experiments = mlflow.list_experiments(view_type=ViewType.ALL)\n",
    "for exp in experiments:\n",
    "    print(exp.name)\n",
    "\n",
    "# Pour récupérer une expérience spécifique, vous pouvez exécuter :\n",
    "exp = mlflow.get_experiment_by_name(experiment_name)\n",
    "print(exp)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Récupérer des exécutions\n",
    "MLflow vous permet de rechercher des exécutions au sein d’une expérience. Vous avez besoin de l’ID de l’expérience ou de son nom.\n",
    "\n",
    "Par exemple, lorsque vous souhaitez récupérer les métriques d’une exécution spécifique :\n",
    "```python\n",
    "import mlflow\n",
    "mlflow.search_runs(exp.experiment_id)\n",
    "\n",
    "# Get the run id for the experiment and model name\n",
    "run_id = mlflow.search_runs(exp.experiment_id, filter_string=\"tags.mlflow.runName = 'model'\").iloc[0].run_id\n",
    "\n",
    "# Get the metrics for the run\n",
    "mlflow.get_run(run_id).data.metrics\n",
    "```\n",
    "\n",
    "Vous pouvez effectuer des recherches sur plusieurs expériences si nécessaire. La recherche à travers les expériences peut être utile si vous souhaitez comparer les exécutions d’un même modèle lorsqu’il est journalisé dans différentes expériences (par différentes personnes ou différentes itérations de projet).\n",
    "\n",
    "Vous pouvez utiliser search_all_experiments=True si vous souhaitez effectuer une recherche sur toutes les expériences de l’espace de travail.\n",
    "\n",
    "Par défaut, les expériences sont triées par ordre décroissant de start_time, c’est-à-dire le moment où l’expérience a été mise en file d’attente dans Azure Machine Learning. Toutefois, vous pouvez modifier cette valeur par défaut à l’aide du paramètre order_by.\n",
    "\n",
    "Par exemple, si vous souhaitez trier par heure de début et afficher uniquement les deux derniers résultats :\n",
    "```python   \n",
    "import mlflow\n",
    "#mlflow.search_runs(order_by=[\"metrics.accuracy DESC\"], max_results=2)\n",
    "mlflow.search_runs(exp.experiment_id, order_by=[\"start_time DESC\"], max_results=2)\n",
    "```\n",
    "\n",
    "\n",
    "Vous pouvez également rechercher une exécution avec une combinaison spécifique dans les hyperparamètres :\n",
    "```python\n",
    "mlflow.search_runs(\n",
    "    exp.experiment_id, filter_string=\"params.num_boost_round='100'\", max_results=2\n",
    ")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
