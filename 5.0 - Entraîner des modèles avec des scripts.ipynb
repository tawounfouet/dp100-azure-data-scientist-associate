{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertir un notebook en script\n",
    "\n",
    "Si vous avez utilisé des notebooks pour l’expérimentation et le développement, vous devez d’abord convertir un notebook en script. Vous pouvez également choisir de ne pas utiliser de notebooks et de travailler uniquement avec des scripts. Dans les deux cas, pour préparer votre code pour la production, vous devez appliquer certaines recommandations lors de la création de scripts.\n",
    "\n",
    "Les scripts conviennent parfaitement aux tests et à l’automatisation dans votre environnement de production. Pour créer un script prêt pour la production, vous devez :\n",
    "\n",
    "### Supprimer le code non essentiel ;\n",
    "- refactoriser votre code en fonctions ;\n",
    "- tester votre script dans le terminal.\n",
    "- Supprimer tout le code non essentiel\n",
    "Le principal avantage de l’utilisation de notebooks est de pouvoir explorer rapidement des données. Par exemple, vous pouvez utiliser les instructions print() et df.describe() pour explorer vos données et vos variables. Quand vous créez un script qui sera utilisé pour l’automatisation, évitez d’inclure du code écrit à des fins exploratoires.\n",
    "\n",
    "La première chose que vous devez donc faire pour convertir votre code en code de production est de supprimer le code non essentiel. En particulier, quand vous exécutez le code régulièrement, omettez tout ce qui n’est pas essentiel pour réduire les coûts et le temps de calcul."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactoriser le code en fonctions\n",
    "Quand vous utilisez du code dans des processus métier, le code doit être facile à lire pour que tout le monde puisse le gérer. Une approche courante pour rendre le code plus facile à lire et à tester consiste à utiliser des fonctions.\n",
    "\n",
    "Par exemple, vous avez peut-être utilisé l’exemple de code suivant dans un notebook pour lire et fractionner les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and visualize the data\n",
    "print(\"Reading data...\")\n",
    "df = pd.read_csv('diabetes.csv')\n",
    "df.head()\n",
    "\n",
    "# split data\n",
    "print(\"Splitting data...\")\n",
    "X, y = df[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, df['Diabetic'].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la mesure où les fonctions permettent également de tester des parties de votre code, vous pouvez créer plusieurs fonctions plus petites plutôt qu’une grande fonction. Si vous souhaitez tester une partie de votre code, vous pouvez choisir de tester uniquement une petite partie en veillant à ne pas exécuter plus de code que nécessaire.\n",
    "\n",
    "Vous pouvez refactoriser le code présenté dans l’exemple en deux fonctions :\n",
    "\n",
    "Lire les données\n",
    "Fractionner les données\n",
    "Voici un exemple de code refactorisé :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(csv_file):\n",
    "    # read data\n",
    "    df = get_data(csv_file)\n",
    "\n",
    "    # split data\n",
    "    X_train, X_test, y_train, y_test = split_data(df)\n",
    "\n",
    "# function that reads the data\n",
    "def get_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# function that splits the data\n",
    "def split_data(df):\n",
    "    X, y = df[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness',\n",
    "    'SerumInsulin','BMI','DiabetesPedigree','Age']].values, df['Diabetic'].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exécuter un script en tant que travail de commande\n",
    "\n",
    "Quand vous avez un script qui entraîne un modèle Machine Learning, vous pouvez l’exécuter en tant que travail de commande dans Azure Machine Learning.\n",
    "\n",
    "### Configurer et soumettre un travail de commande\n",
    "Pour exécuter un script en tant que travail de commande, vous devez configurer et soumettre le travail.\n",
    "\n",
    "Pour configurer un travail de commande avec le SDK Python (v2), vous utiliserez la fonction command. Pour exécuter un script, vous devez spécifier des valeurs pour les paramètres suivants :\n",
    "\n",
    "- `code`: dossier contenant le script à exécuter.\n",
    "- `command`: spécifie le fichier à exécuter.\n",
    "- `environment`: packages nécessaires à installer sur le calcul avant d’exécuter la commande.\n",
    "- `compute`: calcul à utiliser pour exécuter la commande.\n",
    "- `display_name`: nom du travail individuel.\n",
    "- `experiment_name`: nom de l’expérience à laquelle le travail appartient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "\n",
    "# configure job\n",
    "job = command(\n",
    "    code=\"./src\",\n",
    "    command=\"python train.py\",\n",
    "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
    "    compute=\"aml-cluster\",\n",
    "    display_name=\"train-model\",\n",
    "    experiment_name=\"train-classification-model\"\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois votre travail configuré, vous pouvez le soumettre, ce qui a pour effets de le lancer et d’exécuter le script :\n",
    "```python\n",
    "# submit job\n",
    "returned_job = ml_client.create_or_update(job)\n",
    "```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utiliser des paramètres dans un travail de commande\n",
    "\n",
    "Vous pouvez augmenter la flexibilité de vos scripts en utilisant des paramètres. Par exemple, vous avez peut-être créé un script qui entraîne un modèle Machine Learning. Vous pouvez utiliser le même script pour entraîner un modèle sur différents jeux de données ou à l’aide de différentes valeurs d’hyperparamètres.\n",
    "\n",
    "### Utilisation d’arguments de script\n",
    "Pour utiliser des paramètres dans un script, vous devez utiliser une bibliothèque telle que argparse pour lire les arguments passés au script et les affecter à des variables.\n",
    "\n",
    "Par exemple, le script suivant lit un argument nommé training_data qui spécifie le chemin aux données d’entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def main(args):\n",
    "    # read data\n",
    "    df = get_data(args.training_data)\n",
    "\n",
    "# function that reads the data\n",
    "def get_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def parse_args():\n",
    "    # setup arg parser\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # add arguments\n",
    "    parser.add_argument(\"--training_data\", dest='training_data',\n",
    "                        type=str)\n",
    "\n",
    "    # parse args\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # return args\n",
    "    return args\n",
    "\n",
    "# run script\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # parse args\n",
    "    args = parse_args()\n",
    "\n",
    "    # run main function\n",
    "    main(args)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passage d’arguments à un script\n",
    "Pour passer des valeurs de paramètre à un script, vous devez fournir la valeur de l’argument dans la commande.\n",
    "\n",
    "Par exemple, si vous passez une valeur de paramètre lors de l’exécution d’un script dans un terminal, utilisez la commande suivante :\n",
    "\n",
    "```python\n",
    "python train.py --training_data diabetes.csv\n",
    "```\n",
    "\n",
    "Dans l’exemple, `diabetes.csv` est un fichier local. Vous pouvez également spécifier le chemin à une ressource de données créée dans l’espace de travail Azure Machine Learning.\n",
    "\n",
    "De même, pour passer une valeur de paramètre à un script que vous souhaitez exécuter en tant que travail de commande, vous devez spécifier les valeurs dans la commande :\n",
    "\n",
    "```python\n",
    "from azure.ai.ml import command\n",
    "\n",
    "# configure job\n",
    "job = command(\n",
    "    code=\"./src\",\n",
    "    command=\"python train.py --training_data diabetes.csv\",\n",
    "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
    "    compute=\"aml-cluster\",\n",
    "    display_name=\"train-model\",\n",
    "    experiment_name=\"train-classification-model\"\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
